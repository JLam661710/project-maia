# 架构重构规划 v2 (最终确认版)

## 1. 核心逻辑：全周期响应优先 (Response-First Loop)

根据你的最新指示，取消“首轮特殊处理”，全流程统一采用 **"回复 -> 后台分析"** 模式。Interviewer 将依靠自身对上下文的理解能力应对当前轮次，Analyst 仅负责为下一轮制定战略。

### 统一循环逻辑 (Main Loop)
1.  **用户输入 (User Input)**: 接收用户消息。
2.  **立即响应 (Interviewer Reply)**: 
    *   基于 **上一轮** 沉淀的 `system_notice` 和当前对话历史，立即生成并输出回复。
    *   *用户体验*: 此时前端开始播放语音（模拟）。
3.  **锁定输入 (Input Lock)**: 
    *   输出提示: `[System] 正在同步访谈记录与后台分析... (语音播报中，暂停输入)`
4.  **后台处理 (Background Processing)**:
    *   **Analyst**: 分析 [最新用户输入 + Interviewer 刚生成的回复]。更新 State 和下一轮的 `system_notice`。
    *   **Judge** (按需触发): 评估本轮交互质量，修正下一轮指令。
    *   **Summary** (按需触发): 压缩历史。
5.  **解锁 (Unlock)**: 允许用户进行下一轮输入。

---

## 2. 代码执行计划

我将直接修改 `main.py`，主要改动如下：

*   **调整执行顺序**: 将 `interviewer.generate_reply()` 移至 `analyst.analyze_turn()` 之前。
*   **优化历史记录构建**: 确保 Analyst 分析时能看到 Interviewer 刚刚说出的那句话（这对 Analyst 判断“是否已问过某问题”至关重要）。
*   **增加用户提示**: 在后台计算期间显式打印状态信息，模拟“前端禁言”体验。

---

## 3. 预期效果
*   **响应速度**: 提升显著，用户发完言后能立刻得到反馈（开始听语音）。
*   **等待感**: 被语音播报时间所掩盖（Masked Latency）。
*   **安全性**: 依靠 LLM 自身的上下文理解能力兜底当前轮次，依靠 Analyst/Judge 在下一轮进行纠偏。

准备就绪，等待你的最终确认即刻开始开发。
